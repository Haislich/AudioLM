{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from audiolm.data_preparation import AudioDataLoader\n",
    "from audiolm.w2v_hubert import W2VHuBert\n",
    "from audiolm.absolute_transformer import SemanticTransformer\n",
    "from audiolm.trainer import SemanticTrainer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "torch.set_warn_always(False)\n",
    "\n",
    "SAVE_PATH = Path(os.getcwd() + \"\\\\data\\\\datasets\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========================================\n",
      "End to end Pipeline for semantic modelling.\n",
      "===========================================\n",
      "Created generator.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josed\\Documents\\AudioLM\\.venv\\lib\\site-packages\\torch\\nn\\utils\\weight_norm.py:28: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modello caricato\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\josed\\Documents\\AudioLM\\.venv\\lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MiniBatchKMeans from version 0.24.0 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans caricato\n",
      "Created encoder.\n",
      "Created transformer.\n",
      "Fetched Dataloader and divided in train, test and validation.\n",
      "Created cross entropy loss\n",
      "Adam\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30f52684906d4df7aa3c45eb8292935c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "semantic_encode shape: torch.Size([1, 149])\n",
      "Generate output: torch.Size([148, 500]) and target:torch.Size([148])\n",
      "semantic_encode shape: torch.Size([1, 149])\n",
      "Generate output: torch.Size([148, 500]) and target:torch.Size([148])\n",
      "semantic_encode shape: torch.Size([1, 149])\n",
      "Generate output: torch.Size([148, 500]) and target:torch.Size([148])\n",
      "semantic_encode shape: torch.Size([1, 149])\n",
      "Generate output: torch.Size([148, 500]) and target:torch.Size([148])\n",
      "Checkpoint saved: c:\\Users\\josed\\Documents\\AudioLM\\notebooks\\..\\data\\models\n",
      "Model saved: c:\\Users\\josed\\Documents\\AudioLM\\notebooks\\..\\data\\models\\SemanticTransformer.pth\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Test if the pipeline generate a single emebeding\"\"\"\n",
    "print(\"===========================================\")\n",
    "print(\"End to end Pipeline for semantic modelling.\")\n",
    "print(\"===========================================\")\n",
    "\n",
    "print(\"Created generator.\")\n",
    "semantic_encoder = W2VHuBert()\n",
    "print(\"Created encoder.\")\n",
    "semantic_transformer = SemanticTransformer()\n",
    "print(\"Created transformer.\")\n",
    "dataloader = AudioDataLoader(os.getcwd() + \"\\\\..\\\\data\\\\datasets\", batch_size=1)\n",
    "print(\"Fetched Dataloader and divided in train, test and validation.\")\n",
    "loss = nn.CrossEntropyLoss()\n",
    "print(\"Created cross entropy loss\")\n",
    "optimizer = torch.optim.Adam(semantic_transformer.parameters(), lr=0.001)\n",
    "print(\"Adam\")\n",
    "intervals = 10\n",
    "save_path = Path(os.getcwd() + \"\\\\..\\\\data\\\\\")\n",
    "early_stop_counter = 10\n",
    "early_stopping_range = 10\n",
    "epochs = 1\n",
    "semantic_trainer = SemanticTrainer(\n",
    "    semantic_encoder=semantic_encoder,\n",
    "    semantic_transformer=semantic_transformer,\n",
    "    train_dataloader=dataloader,\n",
    "    val_dataloader=dataloader,\n",
    "    test_dataloader=dataloader,\n",
    "    loss=loss,\n",
    "    optimizer=optimizer,\n",
    "    intervals=intervals,\n",
    "    save_path=save_path,\n",
    "    early_stop_counter=early_stop_counter,\n",
    "    early_stopping_range=early_stopping_range,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "semantic_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-d907f741e8b411a3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-d907f741e8b411a3\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6013;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "%tensorboard --logdir \".\\\\..\\\\data\\\\runs\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
