{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haislich/AudioLM/blob/semantic_modeling/AudioLM_notebook_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZV3wbF6X_t63",
        "outputId": "bf32e0df-8813-4172-e44f-d53c1b6099db"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation"
      ],
      "metadata": {
        "id": "afIICT1doURj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/libri-light.git\n",
        "!git clone https://github.com/Haislich/AudioLM.git"
      ],
      "metadata": {
        "id": "xTOmq99goYTA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ed189d-dd2d-4e99-c062-15b48953cb5a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'libri-light'...\n",
            "remote: Enumerating objects: 178, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 178 (delta 8), reused 17 (delta 5), pack-reused 155\u001b[K\n",
            "Receiving objects: 100% (178/178), 374.49 KiB | 1.49 MiB/s, done.\n",
            "Resolving deltas: 100% (62/62), done.\n",
            "Cloning into 'AudioLM'...\n",
            "remote: Enumerating objects: 190, done.\u001b[K\n",
            "remote: Counting objects: 100% (190/190), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 190 (delta 78), reused 148 (delta 42), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (190/190), 13.04 MiB | 20.06 MiB/s, done.\n",
            "Resolving deltas: 100% (78/78), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python /content/libri-light/data_preparation/build_all_stats.py /content/drive/MyDrive/AudioLMDataset/datasets_raw/small/small /content/drive/MyDrive/AudioLMDataset/ecciu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "louGw6iIuOGn",
        "outputId": "770e6438-187b-47bc-9d15-0d698e14c2c6"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gathering the list of metadata\n",
            "No cache found at /content/drive/MyDrive/AudioLMDataset/ecciu/.cache/metadata.pkl\n",
            "Saving a cache at /content/drive/MyDrive/AudioLMDataset/ecciu/.cache/metadata.pkl\n",
            "2588 files found\n",
            "Building the genre statistics\n",
            "No cache found at /content/drive/MyDrive/AudioLMDataset/ecciu/.cache/meta_genre_stats.json\n",
            "  2% (59 of 2588) |                                           | Elapsed Time: 0:01:01 ETA:   0:48:40^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "4ZJLU4eMXFh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from transformers import Wav2Vec2BertModel, AutoProcessor\n",
        "import torch\n",
        "import random as rd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "mO0-NPUUsp45"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classes"
      ],
      "metadata": {
        "id": "_di1MNzmW5DG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utils"
      ],
      "metadata": {
        "id": "mzItcArHW8d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed):\n",
        "    rd.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def count_flac(data_path):\n",
        "  data_list = os.walk(data_path)\n",
        "  cnt=0\n",
        "\n",
        "  for dirpath, dirnames, filenames in data_list:\n",
        "    for filename in filenames:\n",
        "      path_to_audio = os.path.join(dirpath, filename)\n",
        "      if path_to_audio.endswith(\".flac\"):\n",
        "        cnt+=1\n",
        "\n",
        "  return cnt"
      ],
      "metadata": {
        "id": "S-YGmHvOW7cu"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing"
      ],
      "metadata": {
        "id": "k2sZP4vrQKYA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "ejBjUPqXHp5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = \"/content/drive/MyDrive/AudioLMDataset/dataset_segmented\"\n",
        "#dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
        "processor = AutoProcessor.from_pretrained(\"hf-audio/wav2vec2-bert-CV16-en\")\n",
        "model = Wav2Vec2BertModel.from_pretrained(\"hf-audio/wav2vec2-bert-CV16-en\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8JY9tA0Guqt",
        "outputId": "eedb06ff-b2a8-417b-cc4d-ae3410ad237a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def from_audio_2_embeddings(data_path, max_files=None):\n",
        "  data_list = os.walk(data_path)\n",
        "  audio_embeddings = []\n",
        "  cnt=0\n",
        "  total = count_flac(data_path)\n",
        "\n",
        "  if max_files != None:\n",
        "    total = max_files\n",
        "\n",
        "\n",
        "  pbar = tqdm(total=total, desc=\"Featuring audios...\")\n",
        "\n",
        "  for dirpath, dirnames, filenames in data_list:\n",
        "    for filename in filenames:\n",
        "      path_to_audio = os.path.join(dirpath, filename)\n",
        "      if path_to_audio.endswith(\".flac\"):\n",
        "        audio, sr = librosa.load(path_to_audio, sr=None)  # load audio file with librosa library and sample rate 16kHz\n",
        "        #print(len(audio))\n",
        "        inputs = processor(audio, return_tensors=\"pt\", sampling_rate=sr) # extract features from audio file with processor\n",
        "        print(inputs)\n",
        "        output = model(inputs['input_features'], output_hidden_states=True, return_dict=True)\n",
        "        seventh_layer_output = output.hidden_states[6] # get the output of the 7th layer of BERT model\n",
        "        audio_embeddings.append(seventh_layer_output.squeeze(0).detach().numpy())\n",
        "        cnt+=1\n",
        "        pbar.update(1)\n",
        "        if cnt >= total:\n",
        "          break\n",
        "\n",
        "\n",
        "  pbar.close()\n",
        "\n",
        "  audio_embeddings = np.concatenate(audio_embeddings, axis=0)\n",
        "\n",
        "  return audio_embeddings\n",
        "\n",
        "\n",
        "def test_function(demo_dataset):\n",
        "  demo_dataset = demo_dataset.sort(\"id\")\n",
        "  sr = demo_dataset.features[\"audio\"].sampling_rate\n",
        "  audio_embeddings = []\n",
        "\n",
        "  for audios in (demo_dataset):\n",
        "    input = processor(audios[\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=sr)\n",
        "    output = model(input['input_features'], output_hidden_states=True, return_dict=True)\n",
        "    seventh_layer_output = output.hidden_states[6] # get the output of the 7th layer of BERT model\n",
        "    audio_embeddings.append(seventh_layer_output.squeeze(0).detach().numpy())\n",
        "\n",
        "\n",
        "  audio_embeddings = np.concatenate(audio_embeddings, axis=0)\n",
        "\n",
        "  return audio_embeddings\n",
        "\n",
        "def from_embd_to_semToken(audio_embeddings):\n",
        "    scaler = StandardScaler()\n",
        "    audio_embeddings = scaler.fit_transform(audio_embeddings)\n",
        "\n",
        "    k_means = KMeans(n_clusters=1024, random_state=42)\n",
        "    k_means.fit(audio_embeddings)\n",
        "\n",
        "    return k_means.labels_\n",
        "\n",
        "#audio_embed = from_audio_2_embeddings(dataset, 10)\n",
        "#semantic_tokens = from_embd_to_semToken(audio_embed)\n",
        "\n",
        "#semantic_tokens\n",
        "\n"
      ],
      "metadata": {
        "id": "DG29kWALHReG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_em = from_audio_2_embeddings(dataset)\n",
        "semantic_tokens = from_embd_to_semToken(audio_em)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXzN9ic4vPPJ",
        "outputId": "54928466-f17d-4c86-f090-98ea0e141cd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Featuring audios...:   0%|          | 0/36229 [00:00<?, ?it/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00036621 -0.00036621 -0.00042725 ...  0.00057983  0.00048828\n",
            "  0.00033569]\n",
            "{'input_features': tensor([[[-2.1301, -1.9912, -1.5485,  ..., -1.7942, -1.8913, -2.2307],\n",
            "         [-1.6300, -1.3804, -1.4738,  ..., -1.4663, -1.5525, -1.8901],\n",
            "         [-1.0104, -0.9717, -1.2421,  ..., -1.4721, -1.4840, -1.7839],\n",
            "         ...,\n",
            "         [-0.9875, -1.1265, -0.9915,  ..., -2.0437, -2.0837, -2.2086],\n",
            "         [-1.4624, -1.6142, -1.3722,  ..., -1.7880, -2.0405, -2.3680],\n",
            "         [-1.5119, -1.5796, -2.1517,  ..., -1.9141, -1.9322, -2.3005]]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Featuring audios...:   0%|          | 1/36229 [00:14<144:02:26, 14.31s/it]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.00357056  0.00427246  0.00567627 ... -0.0072937  -0.00799561\n",
            " -0.00796509]\n",
            "{'input_features': tensor([[[-1.1680, -1.2422, -1.6384,  ..., -1.0660, -0.8002, -0.8915],\n",
            "         [ 1.0473,  0.5893, -0.1861,  ..., -1.0661, -0.8358, -0.7779],\n",
            "         [ 0.8739,  0.2553, -1.0427,  ..., -1.3063, -0.9323, -0.6504],\n",
            "         ...,\n",
            "         [-1.9303, -1.9827, -1.5939,  ..., -0.6047, -0.6532, -0.5503],\n",
            "         [-2.0955, -1.9896, -2.1080,  ..., -0.6099, -0.4032, -0.7376],\n",
            "         [-0.4362, -0.7825, -1.2963,  ..., -0.7788, -0.8508, -0.8202]]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "semantic_tokens"
      ],
      "metadata": {
        "id": "1-nbIct7wOUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(semantic_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1o9CbH1jmQv",
        "outputId": "966022a8-0bf6-46a0-cbe6-98e5416c8e35"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23998"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Wav2Vec2BertModel, AutoFeatureExtractor\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Carica il dataset\n",
        "dataset = load_dataset(\"hf-internal-testing/librispeech_asr_demo\", \"clean\", split=\"validation\")\n",
        "dataset = dataset.sort(\"id\")\n",
        "sampling_rate = dataset.features[\"audio\"].sampling_rate\n",
        "\n",
        "# Carica il modello e l'estrattore di feature\n",
        "processor = AutoFeatureExtractor.from_pretrained(\"facebook/w2v-bert-2.0\")\n",
        "model = Wav2Vec2BertModel.from_pretrained(\"facebook/w2v-bert-2.0\")\n",
        "\n",
        "inputs = processor(dataset[0][\"audio\"][\"array\"], sampling_rate=sampling_rate, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "8t_HN1fc08DB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0][\"audio\"][\"array\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYSBSSvJBBCJ",
        "outputId": "84e31e71-8230-4d6f-c539-21852e3b2c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00042725, 0.00057983,\n",
              "       0.0010376 ])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(inputs['input_features'], output_hidden_states=True, return_dict=True)\n",
        "seventh_layer_output = outputs.hidden_states[6]\n",
        "seventh_layer_output\n"
      ],
      "metadata": {
        "id": "IHGPsG_U8Hx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seventh_layer_output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFqwV1nw94Ei",
        "outputId": "60bf8e43-b13f-4d5e-c99e-7fd2821fca59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.1476,  0.0026, -0.2191,  ..., -0.3142, -0.1849, -0.2700],\n",
              "         [-0.0255,  0.1388,  0.1583,  ..., -0.0269,  0.2433, -0.2006],\n",
              "         [ 0.0260,  0.1063,  0.0102,  ..., -0.0240, -0.0181, -0.0301],\n",
              "         ...,\n",
              "         [ 0.2395,  0.1679,  0.1687,  ..., -0.2784,  0.0184, -0.0730],\n",
              "         [ 0.1917,  0.2821,  0.2182,  ..., -0.2251, -0.0072,  0.0939],\n",
              "         [ 0.2303,  0.0882, -0.2248,  ..., -0.2103,  0.0014,  0.0202]]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seventh_layer_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnS2tSN-5U81",
        "outputId": "00941c2f-d6cc-4d8c-8fcb-dfda76512bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 292, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}